{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0q-uuiyoovBX"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader,random_split,Dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer,AutoModelForSequenceClassification"
      ],
      "metadata": {
        "id": "ym_fCA5Go55L"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "c= 0;\n",
        "texts = []\n",
        "labels = []\n",
        "for i in range(1,9):\n",
        "    dirname = f'/content/drive/MyDrive/Golestan/gbab{i}'\n",
        "    for j in range(1,len(os.listdir(dirname))+1):\n",
        "        filename = dirname + '/'+f'hekayat{j}.txt'\n",
        "        with open(filename,encoding='utf-8') as f :\n",
        "            texts.append(f.readlines()[0]);\n",
        "            labels.append(i-1)\n"
      ],
      "metadata": {
        "id": "xzLvV9PRo7xD"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "texts = [re.sub(r'[\\u064B-\\u0652]','',t) for t in texts];\n",
        "texts[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "id": "mrPEuEVmpADm",
        "outputId": "a1d0541d-e1e2-4c57-dcf7-4ee888782c24"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'پادشاهی را شنیدم به کشتن اسیری اشارت کرد بی چاره در آن حالت نومیدی ملک را دشنام دادن گرفت و سقط گفتن که گفته اند هر که دست از جان بشوید هر چه در دل دارد بگوید وقت ضرورت چو نماند گریز دست بگیرد سر شمشیر تیز إذا یئس الإنسان طال لسانه کسنور مغلوب یصول علی الکلب ملک پرسید چه می گوید یکی از وزرای نیک محضر گفت ای خداوند همی گوید و الکاظمین الغیظ و العافین عن الناس ملک را رحمت آمد و از سر خون او درگذشت وزیر دیگر که ضد او بود گفت ابنای جنس ما را نشاید در حضرت پادشاهان جز به راستی سخن گفتن این ملک را دشنام داد و ناسزا گفت ملک روی از این سخن در هم آورد و گفت آن دروغ وی پسندیده تر آمد مرا زین راست که تو گفتی که روی آن در مصلحتی بود و بنای این بر خبثی و خردمندان گفته اند دروغی مصلحت آمیز به که راستی فتنه انگیز هر که شاه آن کند که او گوید حیف باشد که جز نکو گوید بر طاق ایوان فریدون نبشته بود جهان ای برادر نماند به کس دل اندر جهان آفرین بند و بس مکن تکیه بر ملک دنیا و پشت که بسیار کس چون تو پرورد و کشت چو آهنگ رفتن کند جان پاک چه بر تخت مردن چه بر روی خاک '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/Golestan/stopwords.txt',encoding='utf-8') as f :\n",
        "    stopwords = set(f.read().split('\\n'))"
      ],
      "metadata": {
        "id": "7quSCVZPpB0c"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'HooshvareLab/bert-fa-base-uncased';\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name) ;"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R11k_ORRpDdE",
        "outputId": "f2f51fe2-a835-4422-cf16-4f77e7aff7b2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Text(Dataset):\n",
        "  def __init__(self, texts,labels,tokenizer):\n",
        "    super().__init__();\n",
        "    self.texts = texts;\n",
        "    self.tokenizer = tokenizer ;\n",
        "    self.labels = labels;\n",
        "  def __len__(self) : return len(self.texts);\n",
        "  def __getitem__(self, index):\n",
        "    text = self.texts[index];\n",
        "    label = self.labels[index];\n",
        "    tokens = self.tokenizer(text,truncation=True,max_length = 512,padding='max_length',\n",
        "                            return_tensors='pt');\n",
        "    item = {key:val.squeeze(0) for key,val in tokens.items()};\n",
        "    item['labels'] = torch.tensor(label,dtype=torch.int64);\n",
        "    return item"
      ],
      "metadata": {
        "id": "aRC9j3GKpGVr"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = Text(texts,labels,tokenizer);\n",
        "dataset[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uKiwBTTPpH8Y",
        "outputId": "c8cc2fbf-b023-4621-890f-df7e67b0d283"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([    2,  6131,  2803, 18426,  2789,  9745, 45564, 54965,  2830,  2883,\n",
              "         15251,  2786,  2808,  4157, 48198,  6722,  2803, 38060,  4186,  3153,\n",
              "          1379, 14067,  8540,  2800,  3538,  3145,  2937,  2800,  2910,  2791,\n",
              "          3607, 19718,  2937,  3051,  2786,  3217,  2924,  9531,  4244,  7109,\n",
              "         16176, 11659, 12120,  2910,  4962,  2892, 10626, 10426, 36766, 89480,\n",
              "          2017, 78595,  8342, 16255,  2008, 73739,  2795, 12670,  1442,  3516,\n",
              "          3366,  9354,  2016,  6722, 10840,  3051,  2793, 18889,  3036,  2791,\n",
              "         10224,  7513, 15513,  3017,  2938,  6512, 27131, 18889,  1379, 70372,\n",
              "          2788, 78592,  2062,  1379,  5679, 45570,  5701, 25289,  6722,  2803,\n",
              "         13823,  3771,  1379,  2791,  2892,  4266,  2866,  5661,  3646,  2972,\n",
              "          2800,  4698,  2866,  2834,  3017, 98935,  6586,  2964,  2803, 41265,\n",
              "          2805,  2786,  5883, 10487,  3430,  2789, 12320,  4402,  8540,  2802,\n",
              "          6722,  2803, 38060,  2974,  1379, 30606,  3017,  6722,  3040,  2791,\n",
              "          2802,  4402,  2786,  2820,  3922,  1379,  3017,  2808,  7693,  2931,\n",
              "         23237,  3088,  3771,  3306,  7946,  4272,  2800,  2861, 33120,  2800,\n",
              "          3040,  2808,  2786, 45640,  2834,  1379,  7183,  2802,  2801,  8039,\n",
              "          5855,  1379, 55021,  3538,  3145, 36888, 10367,  8192,  2789,  2800,\n",
              "         12320,  8996,  6516,  2937,  2800,  3603,  2808,  3054,  2800,  2866,\n",
              "         18889, 23317,  3048,  2800,  3430, 40981, 18889,  2801,  8665,  8354,\n",
              "         10887, 33854,  2834,  3381,  2938,  4705, 11659,  2789,  3382,  3217,\n",
              "         11840,  3381,  9808,  4432,  1379,  5139, 18969,  7855,  2801,  6722,\n",
              "          3810,  1379,  3759,  2800,  3177,  3382,  3633,  2861, 15359,  1379,\n",
              "          4005, 16176,  4954,  5200,  3054,  3607,  4679,  3051,  2801,  5846,\n",
              "         22574,  3051,  2801,  3040,  4361,     4,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0]),\n",
              " 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
              " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
              " 'labels': tensor(0)}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "_KjvGH6Cqnxr"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset,val_dataset = random_split(dataset,[250,40]);\n",
        "train_loader = DataLoader(train_dataset,batch_size=8,shuffle=True);\n",
        "val_loader = DataLoader(val_dataset,batch_size=8,shuffle=False);"
      ],
      "metadata": {
        "id": "TkhJrGx7pJfN"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda'"
      ],
      "metadata": {
        "id": "qbob45_DpLtg"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = AutoModelForSequenceClassification.from_pretrained('HooshvareLab/bert-fa-base-uncased',\n",
        "                                                            num_labels=8)\n",
        "model1.to(device);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPeeL7kBpND7",
        "outputId": "1672375a-4fc3-49a7-c840-40dc01c8cc84"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at HooshvareLab/bert-fa-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(lr=2e-5,params= model1.parameters());\n",
        "loss_function = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "NrZQF5tqpRe7"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "LLavnYNFqN1l"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10):\n",
        "  model1.train();\n",
        "  for x in train_loader :\n",
        "    optimizer.zero_grad();\n",
        "    attention_mask = x['attention_mask'].to(device);\n",
        "    input_ids = x['input_ids'].to(device);\n",
        "    labels = x['labels'].to(device);\n",
        "    out = model1(attention_mask = attention_mask,labels=labels,input_ids=input_ids);\n",
        "    logits = out.logits;\n",
        "    loss = loss_function(logits,labels);\n",
        "    loss.backward();\n",
        "    optimizer.step();\n",
        "  print(f\"Epoch {i} ---> Loss : {round(loss.item(),4)}\")\n",
        "# Notice that I ran this cell twice."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9dIrkRqxpl-a",
        "outputId": "b30ead57-99dd-45a1-ca3f-b699ad068a8d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 ---> Loss : 0.0373\n",
            "Epoch 1 ---> Loss : 0.0237\n",
            "Epoch 2 ---> Loss : 0.0292\n",
            "Epoch 3 ---> Loss : 0.014\n",
            "Epoch 4 ---> Loss : 0.0063\n",
            "Epoch 5 ---> Loss : 0.0194\n",
            "Epoch 6 ---> Loss : 0.012\n",
            "Epoch 7 ---> Loss : 0.0081\n",
            "Epoch 8 ---> Loss : 0.0029\n",
            "Epoch 9 ---> Loss : 0.0049\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score,f1_score\n",
        "model1.eval();\n",
        "predicts = []\n",
        "y_test = []\n",
        "with torch.no_grad():\n",
        "  for x in val_loader :\n",
        "    attention_mask = x['attention_mask'].to(device);\n",
        "    input_ids = x['input_ids'].to(device);\n",
        "    labels = x['labels'].to(device);\n",
        "    out = model1(attention_mask = attention_mask,labels=labels,input_ids=input_ids);\n",
        "    logits = out.logits;\n",
        "    predict = logits.argmax(1);\n",
        "    predicts.extend(predict.tolist());\n",
        "    y_test.extend(labels.tolist());\n",
        "print(\"Accuracy :\",accuracy_score(y_test,predicts));\n",
        "print(\"F1-score(macro) :\",f1_score(y_test,predicts,average='macro'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0s8_v_GUtBxa",
        "outputId": "6042524a-c872-4038-8de4-6d3c3df4bb04"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy : 0.5\n",
            "F1-score(macro) : 0.3135989010989011\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "A0Bh2mKBuWZ8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}